{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160f7b30",
   "metadata": {},
   "source": [
    "# Logical Computations with Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58edf476",
   "metadata": {},
   "source": [
    "Let there exist 3 neurons A,B,C\n",
    "\n",
    "1. C = A: Neuron C gets activated when neuron A is active. This is essentially the identity.\n",
    "\n",
    "2. C = A $\\wedge$ B: Neuron C gets activated when both A and B are active.\n",
    "\n",
    "3. C = A $\\vee$ B: Neuron C gets activated when A or B are active or both.\n",
    "\n",
    "4. C = A $\\wedge$ $\\neg$B: Neuron C gets activated if neuron A is active and if neuron B is off.\n",
    "\n",
    "Although each network is simple if they combined together in layers they can perform complex logical computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f4c26",
   "metadata": {},
   "source": [
    "# The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793e2b0",
   "metadata": {},
   "source": [
    "The Perceptron is one of the simplest artificial neural networks. It is based on a threshold logic unit (TLU) artificial neuron. The TLU computes a weighted sum of its inputs $z = w_1x_1 + w_2x_2 + \\cdots + w_nx_n = \\bf{x}^Tw$, it then applies a step function to the sum and outputs the result $h_w(\\bf{x})$ $= step(z)$.\n",
    "\n",
    "Common step functions are the heaviside step function and the sign function.\n",
    "\n",
    "\n",
    "heaviside (z) $= \\begin{cases}                \n",
    "                    0:  z < 0 \\\\\n",
    "                    1: z \\geq 0            \n",
    "                   \\end{cases}$\n",
    "\n",
    "sgn(z) $= \\begin{cases} \n",
    "             -1:  z < 0 \\\\ \\\\\n",
    "              0: z = 0  \\\\ \\\\\n",
    "              +1: z > 0\n",
    "           \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4787ab",
   "metadata": {},
   "source": [
    "A single TLU can be used for simple linear binary classification. It computes a linear combination of the input features for each instance and if this combination exceeds a threshold, it outputs the positive class or else the negative class. For example we could classify an iris flower based on the petal length and petal width. We would also need to add an extra bias feature like before. In the training phase we need to compute the weights and bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d34ac7",
   "metadata": {},
   "source": [
    "A Perceptron is composed of a single layer of TLUs. When all the neurons in a layer are connected to every layer in the previous layer (in this case the input layer) it is called a dense layer. The input layer is formed by the input neurons and a bias neuron which always outputs 1. The outputs of a layer of artificial neurons can be computed via\n",
    "\n",
    "\n",
    "$\\Large h_{\\bf{W},\\bf{b}}(\\bf{X}) = \\phi(\\bf{X}\\bf{W} + \\bf{b})$\n",
    "\n",
    "\n",
    "$\\bf{X}$ - The matrix of input features where rows represent each instance and columns represent the features.\n",
    "\n",
    "$\\bf{W}$ - The weight matrix has one row per input neuron and one column per artificial neuron in the layer. For classification this is an n x k matrix.\n",
    "\n",
    "$\\bf{b}$ - The bias vector contains one column per artificial neuron. This a row vector 1 x k.\n",
    "\n",
    "$\\phi$ - This is the activation function which in this case is a step function.\n",
    "\n",
    "\n",
    "### Perceptron Update Rule\n",
    "\n",
    "$w_{i, j} = w_{i, j} + \\eta (y_i - \\hat{y}_j)x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd2d32",
   "metadata": {},
   "source": [
    "# Perception From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0ce7b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2fb13378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "354943ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptronclassifier:\n",
    "    def __init__(self, learning_rate=0.01, epochs=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_classes = len(np.unique(y))\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros((n_features, n_classes))\n",
    "        self.bias = np.zeros((1, n_classes))\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                z = np.dot(x_i, self.weights) + self.bias\n",
    "                y_predicted = self.softmax(z)\n",
    "\n",
    "                y_onehot = np.zeros((1, n_classes))\n",
    "                y_onehot[0, y[idx]] = 1\n",
    "                \n",
    "                update = self.learning_rate * np.outer(x_i, (y_onehot - y_predicted))\n",
    "                self.weights += update\n",
    "                self.bias += self.learning_rate * (y_onehot - y_predicted)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  \n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.softmax(z)\n",
    "        return np.argmax(y_predicted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c0ff28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris().data\n",
    "target = load_iris().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad88598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[:,2:]\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a2ad40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_clf = Perceptronclassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4c206c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "27ff5f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf.predict([[5.7, 2.1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da87bbe9",
   "metadata": {},
   "source": [
    "# Perceptron Class Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a243f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b85029d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Perceptron<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Perceptron.html\">?<span>Documentation for Perceptron</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Perceptron()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percep = Perceptron()\n",
    "percep.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "406dffe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percep.predict([[1.5, 0.1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95215752",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron & Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d95b1a",
   "metadata": {},
   "source": [
    "A Multi-Layer Perceptron (MLP) is composed of one input layer, one or more layers of TLUs called hidden layers, and a output layer. An Artificial Neural Network containing more than 2 hidden layers is called a deep neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a048c",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f04f1f",
   "metadata": {},
   "source": [
    "### Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc1c1b",
   "metadata": {},
   "source": [
    "1. Data is fed into the input layer.\n",
    "2. Data passes through the network layer by layer and at each layer the weighted sum of inputs is calculated and an activation function is applied. This prediction serves as the input for the next layer\n",
    "3. The final output is calculated after the algorithm traverses all the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177f065",
   "metadata": {},
   "source": [
    "### Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fe949a",
   "metadata": {},
   "source": [
    "1. calculate the error at output layer using a loss function.\n",
    "2. calculate the gradient of the loss function with respect to each weight and bias.\n",
    "3. Use the chain rule to propagate errors backward through the network.\n",
    "4. Use gradient descent to update the weights and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb0657",
   "metadata": {},
   "source": [
    "### Forward Pass Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c4a09",
   "metadata": {},
   "source": [
    "Let's Consider a network with 1 input layer, 1 hidden layer and 1 output layer\n",
    "\n",
    "Input layer - 2 neurons (2 features) $\\newline$\n",
    "Hidden layer - 2 neurons $\\newline$\n",
    "Output layer - 1 neuron $\\newline$\n",
    "\n",
    "\n",
    "$x = \\begin{pmatrix}\n",
    "            x_1 & x_2 \n",
    "      \\end{pmatrix}  \n",
    "      = \\begin{pmatrix}\n",
    "            0.5 & 0.8 \n",
    "         \\end{pmatrix} $\n",
    "         \n",
    "The input to hidden weight matrix is\n",
    "\n",
    "$ W^1 = \\begin{pmatrix}\n",
    "            0.2 & 0.4 \\\\\n",
    "            0.5 & 0.1\n",
    "      \\end{pmatrix} $\n",
    "      \n",
    "The bias vector for the hidden layer is\n",
    "\n",
    "$ b^1 = \\begin{pmatrix}\n",
    "            0.1 \\\\\n",
    "            0.2\n",
    "      \\end{pmatrix} $\n",
    "\n",
    "      \n",
    "The hidden to output layer weight matrix is\n",
    "\n",
    "$ W^2 = \\begin{pmatrix}\n",
    "            0.6 \\\\\n",
    "            0.7\n",
    "      \\end{pmatrix} $\n",
    "\n",
    "The bias vector for the output layer is\n",
    "\n",
    "$ b^2 = \\begin{pmatrix}\n",
    "            0.1\n",
    "      \\end{pmatrix} $\n",
    "\n",
    "\n",
    "$z^1 = x^T\\cdot W^1 + b^1 = \\begin{pmatrix}\n",
    "            0.42 \\\\\n",
    "            0.33\n",
    "      \\end{pmatrix} + \\begin{pmatrix}\n",
    "            0.1 \\\\\n",
    "            0.2\n",
    "      \\end{pmatrix} = \\begin{pmatrix}\n",
    "            0.52 \\\\\n",
    "            0.53\n",
    "      \\end{pmatrix} $\n",
    "\n",
    "$a^1 = ReLU(z^1) = \\begin{pmatrix}\n",
    "            max(0, 0.52) \\\\\n",
    "            max(0, 0.53)\n",
    "      \\end{pmatrix} = \\begin{pmatrix}\n",
    "            0.52 \\\\\n",
    "            0.53\n",
    "      \\end{pmatrix} $ \n",
    "      \n",
    "$z^2 = (a^1)^T W^2 + b^2 = 0.52\\cdot 0.6 + 0.53\\cdot 0.7 + 0.1 = 0.783$\n",
    "\n",
    "$a^2 = \\frac{1}{1 + \\exp(-0.783)} \\approx 0.686$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a1c1f",
   "metadata": {},
   "source": [
    "### Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cf7f8",
   "metadata": {},
   "source": [
    "$ \\Large L = \\frac{1}{m}\\sum_{i = 1}^{m}(\\hat{y}_i - y_i)^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac577d",
   "metadata": {},
   "source": [
    "#### Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03701cab",
   "metadata": {},
   "source": [
    "$\\Large \\frac{\\partial L}{\\partial W^l} = \\frac{\\partial L}{\\partial z^l}\\frac{\\partial z^l}{\\partial W^l}$ $\\newline$\n",
    "$\\Large \\frac{\\partial L}{\\partial b^l} = \\frac{\\partial L}{\\partial z^l}\\frac{\\partial z^l}{\\partial b^l}$\n",
    "\n",
    "But\n",
    "\n",
    "$ \\Large z^l = W^l a^{l-1} + b^l$\n",
    "\n",
    "$ \\Large \\frac{\\partial z^l}{\\partial W^l}  = a^{l-1}$ $\\newline$\n",
    "$\\Large \\frac{\\partial z^l}{\\partial b^l} = 1$\n",
    "\n",
    "$\\Large \\frac{\\partial L}{\\partial W^l} = \\frac{\\partial L}{\\partial z^l} \\cdot a^{l-1}$ $\\newline$\n",
    "$\\Large \\frac{\\partial L}{\\partial b^l} = \\frac{\\partial L}{\\partial z^l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc933db2",
   "metadata": {},
   "source": [
    "### Update Rule\n",
    "\n",
    "$\\Large W^l \\leftarrow W^l - \\eta \\frac{\\partial L}{\\partial W^l}$ $ \\newline$\n",
    "$\\Large b^l \\leftarrow b^l - \\eta \\frac{\\partial L}{\\partial b^l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f37ee",
   "metadata": {},
   "source": [
    "### Backward Pass Worked Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c8cd44",
   "metadata": {},
   "source": [
    "Once again our input is\n",
    "\n",
    "$\\Large x = \\begin{pmatrix}\n",
    "            0.5 & 0.8 \n",
    "         \\end{pmatrix} $\n",
    "         \n",
    "Begining at the output layer with $\\hat{y} = a^2$\n",
    "\n",
    "$\\Large L = \\frac{1}{2}(\\hat{y} - y)^2$\n",
    "\n",
    "$\\Large \\frac{\\partial L}{\\partial a^2} = \\hat{y} - y$ $\\newline$\n",
    "$\\Large \\frac{\\partial L}{\\partial z^2} = \\frac{\\partial L}{\\partial a^2} \\frac{\\partial a^2}{\\partial z^2}$ $\\newline$\n",
    "$\\Large \\frac{\\partial a^2}{\\partial z^2} = \\frac{\\partial}{\\partial z^2} \\frac{1}{1 + \\exp(-z^2)} = a^2(1 - a^2)$ $\\newline$\n",
    "$\\Large \\frac{\\partial L}{\\partial z^2} = (\\hat{y} - y)a^2(1 - a^2)$ $\\newline$\n",
    "$\\Large \\frac{\\partial L}{\\partial W^2} = (\\hat{y} - y)a^2(1 - a^2)\\cdot a^1$ $\\newline$\n",
    "$\\Large \\frac{\\partial L}{\\partial b^2} = (\\hat{y} - y)a^2(1 - a^2)$\n",
    "\n",
    "From here we will propagate the gradients to the hidden layer\n",
    "\n",
    "$\\Large \\frac{\\partial L}{\\partial W^1} = \\frac{\\partial L}{\\partial z^1} \\cdot a^{0} = \\frac{\\partial L}{\\partial z^1} \\cdot x $ $\\newline$\n",
    "\n",
    "$\\Large \\frac{\\partial L}{\\partial z^1} = \\frac{\\partial L}{\\partial a^1} \\frac{\\partial a^1}{\\partial z^1} = \\frac{\\partial L}{\\partial z^2}\\frac{\\partial z^2}{\\partial a^1} \\frac{\\partial a^1}{\\partial z^1} = \\frac{\\partial L}{\\partial z^2}W^2 \\frac{\\partial a^1}{\\partial z^1}$\n",
    "\n",
    "$\\Large a^1 = ReLU(z^1) \\implies \\frac{\\partial a^1}{\\partial z^1} = \\begin{cases} \n",
    "             1:  z^1 > 0 \\\\ \\\\\n",
    "              0: z^1 \\leq 0\n",
    "           \\end{cases}$ $\\newline$\n",
    "$\\Large \\frac{\\partial L}{\\partial W^1} = \\frac{\\partial L}{\\partial z^1} \\cdot x$ $\\newline$\n",
    "$\\Large \\frac{\\partial L}{\\partial b^1} = \\frac{\\partial L}{\\partial z^1}$\n",
    "\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "$\\Large W^1 \\leftarrow W^1 - \\eta \\frac{\\partial L}{\\partial W^1}$ $ \\newline$\n",
    "$\\Large b^1 \\leftarrow b^1 - \\eta \\frac{\\partial L}{\\partial b^1}$ $ \\newline$\n",
    "$\\Large W^2 \\leftarrow W^2 - \\eta \\frac{\\partial L}{\\partial W^2}$ $ \\newline$\n",
    "$\\Large b^2 \\leftarrow b^2 - \\eta \\frac{\\partial L}{\\partial b^2}$ $ \\newline$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c2072",
   "metadata": {},
   "source": [
    "# Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b11b6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a22bba00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ba25e196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7c875",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9d0cac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab0e3d",
   "metadata": {},
   "source": [
    "## Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "21eb0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5ef68a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "433ec2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_train = X_train[:5000]/255.0, X_train[5000:]/255.0\n",
    "y_val, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ad65363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fdb5b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"] # class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e4254718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07240c1a",
   "metadata": {},
   "source": [
    "## Creating the Model Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c092a07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ayanle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential() # Creates a sequential model\n",
    "model.add(keras.layers.Flatten(input_shape = (28, 28))) # This is the first layer and it converts the input into a 1D array\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\")) # Then a dense layer is added which computes a weighted sum and \n",
    "                                                      # applies the relu activation function\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\")) # Second Dense layer with 100 neurons and with relu activation\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\")) # Output layer with 10 neurons 1 for each class with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ebb33f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │         \u001b[38;5;34m235,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m30,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15913862",
   "metadata": {},
   "source": [
    "The first hidden layer has a weight matrix with shape $784 \\times 300$ and a bias vector with shape $300 \\times 1$. This adds up to 235,500 parameters. The second hidden layer has a weight matrix with shape $300 \\times 100$ and a bias vector with shape $100 \\times 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b6505",
   "metadata": {},
   "source": [
    "## Accessing the Parameters of the Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "68cf677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d9df960f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "93fff161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "66147f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01159949,  0.0463033 , -0.00091522, ...,  0.0690849 ,\n",
       "        -0.03926382, -0.03165219],\n",
       "       [ 0.0665376 ,  0.02830771, -0.00264778, ..., -0.02514979,\n",
       "         0.01275729, -0.05689385],\n",
       "       [ 0.0529063 , -0.00058437, -0.03623737, ..., -0.00671551,\n",
       "        -0.06173424, -0.06647491],\n",
       "       ...,\n",
       "       [-0.05024421,  0.02925229,  0.05987118, ...,  0.03809766,\n",
       "        -0.03275075, -0.04637779],\n",
       "       [-0.06466208, -0.04050616,  0.05707051, ...,  0.0652281 ,\n",
       "         0.01179118, -0.05947311],\n",
       "       [ 0.02418081,  0.02411465,  0.06693418, ..., -0.04707472,\n",
       "         0.02561715, -0.04155482]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8702cc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da3e1e",
   "metadata": {},
   "source": [
    "The dense layer initialised the weights randomly which is needed to break symmetry. The bias vector can be initialised to zeros or randomly but in this case they were initialised to zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37be1e1",
   "metadata": {},
   "source": [
    "## Compiling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5168386",
   "metadata": {},
   "source": [
    "After a model is created, we must call its compile() method to specify the loss function and the optimizer to use. We can also specify extra metrics to compute during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ed891030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c0b87",
   "metadata": {},
   "source": [
    "Here we are using \"sparse_categorical_crossentropy\" loss because we have sparse labels (for each instance we have a target class index from 0 to 9). If we were using one-hot vectors for the target we would use the \"categorical_cross_entropy\" instead.\n",
    "If were doing binary classification we would use \"binary_cross_entropy\" loss and \"sigmoid\" activation function instead of the \"softmax\" activation function in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3705ac",
   "metadata": {},
   "source": [
    "## Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "526247f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6866 - loss: 0.9914 - val_accuracy: 0.8360 - val_loss: 0.4991\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 903us/step - accuracy: 0.8274 - loss: 0.5018 - val_accuracy: 0.8470 - val_loss: 0.4432\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 906us/step - accuracy: 0.8431 - loss: 0.4517 - val_accuracy: 0.8546 - val_loss: 0.4243\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 863us/step - accuracy: 0.8554 - loss: 0.4155 - val_accuracy: 0.8580 - val_loss: 0.4068\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 922us/step - accuracy: 0.8610 - loss: 0.3967 - val_accuracy: 0.8672 - val_loss: 0.3783\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 869us/step - accuracy: 0.8636 - loss: 0.3854 - val_accuracy: 0.8716 - val_loss: 0.3693\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 913us/step - accuracy: 0.8744 - loss: 0.3628 - val_accuracy: 0.8752 - val_loss: 0.3589\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 915us/step - accuracy: 0.8770 - loss: 0.3509 - val_accuracy: 0.8744 - val_loss: 0.3602\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 902us/step - accuracy: 0.8759 - loss: 0.3462 - val_accuracy: 0.8502 - val_loss: 0.4013\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 879us/step - accuracy: 0.8838 - loss: 0.3338 - val_accuracy: 0.8800 - val_loss: 0.3420\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 949us/step - accuracy: 0.8847 - loss: 0.3222 - val_accuracy: 0.8784 - val_loss: 0.3417\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 944us/step - accuracy: 0.8897 - loss: 0.3095 - val_accuracy: 0.8782 - val_loss: 0.3462\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1000us/step - accuracy: 0.8878 - loss: 0.3118 - val_accuracy: 0.8748 - val_loss: 0.3388\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 877us/step - accuracy: 0.8925 - loss: 0.3001 - val_accuracy: 0.8844 - val_loss: 0.3278\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.8955 - loss: 0.2945 - val_accuracy: 0.8890 - val_loss: 0.3124\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 879us/step - accuracy: 0.8959 - loss: 0.2876 - val_accuracy: 0.8880 - val_loss: 0.3144\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 922us/step - accuracy: 0.8994 - loss: 0.2836 - val_accuracy: 0.8874 - val_loss: 0.3193\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.9003 - loss: 0.2794 - val_accuracy: 0.8914 - val_loss: 0.3107\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 924us/step - accuracy: 0.9024 - loss: 0.2683 - val_accuracy: 0.8886 - val_loss: 0.3076\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 898us/step - accuracy: 0.9030 - loss: 0.2687 - val_accuracy: 0.8910 - val_loss: 0.3045\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 902us/step - accuracy: 0.9072 - loss: 0.2585 - val_accuracy: 0.8884 - val_loss: 0.3107\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 956us/step - accuracy: 0.9073 - loss: 0.2588 - val_accuracy: 0.8872 - val_loss: 0.3152\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - accuracy: 0.9090 - loss: 0.2570 - val_accuracy: 0.8848 - val_loss: 0.3086\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2484 - val_accuracy: 0.8886 - val_loss: 0.3066\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 919us/step - accuracy: 0.9117 - loss: 0.2497 - val_accuracy: 0.8948 - val_loss: 0.2940\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 995us/step - accuracy: 0.9135 - loss: 0.2394 - val_accuracy: 0.8902 - val_loss: 0.3059\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2348 - val_accuracy: 0.8952 - val_loss: 0.2963\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 962us/step - accuracy: 0.9174 - loss: 0.2299 - val_accuracy: 0.8924 - val_loss: 0.3027\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 885us/step - accuracy: 0.9201 - loss: 0.2254 - val_accuracy: 0.8902 - val_loss: 0.3003\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 870us/step - accuracy: 0.9189 - loss: 0.2274 - val_accuracy: 0.8992 - val_loss: 0.2855\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf5ab9",
   "metadata": {},
   "source": [
    "Since the training accuracy and the validation accuracy are close there is not much overfitting happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "175023a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 'auto', 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.params # training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "833d9d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 29)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.epoch[0], fit.epoch[-1] # list of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f8b26c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7662000060081482,\n",
       "  0.8297091126441956,\n",
       "  0.8464909195899963,\n",
       "  0.8556908965110779,\n",
       "  0.8620545268058777,\n",
       "  0.8668000102043152,\n",
       "  0.8723636269569397,\n",
       "  0.8760363459587097,\n",
       "  0.8790909051895142,\n",
       "  0.8822363615036011,\n",
       "  0.8843272924423218,\n",
       "  0.8876000046730042,\n",
       "  0.8881818056106567,\n",
       "  0.8912727236747742,\n",
       "  0.8947454690933228,\n",
       "  0.8958908915519714,\n",
       "  0.8984545469284058,\n",
       "  0.8999272584915161,\n",
       "  0.9017817974090576,\n",
       "  0.9021272659301758,\n",
       "  0.9063090682029724,\n",
       "  0.9072545170783997,\n",
       "  0.9095090627670288,\n",
       "  0.9099818468093872,\n",
       "  0.9116727113723755,\n",
       "  0.9132363796234131,\n",
       "  0.9144726991653442,\n",
       "  0.9167818427085876,\n",
       "  0.9176909327507019,\n",
       "  0.9193817973136902],\n",
       " 'loss': [0.7151113152503967,\n",
       "  0.4880254864692688,\n",
       "  0.4407733380794525,\n",
       "  0.4128735661506653,\n",
       "  0.39301949739456177,\n",
       "  0.3772844672203064,\n",
       "  0.36360806226730347,\n",
       "  0.3509015738964081,\n",
       "  0.3417072892189026,\n",
       "  0.3324117958545685,\n",
       "  0.3238285481929779,\n",
       "  0.31581902503967285,\n",
       "  0.3090669512748718,\n",
       "  0.3028579652309418,\n",
       "  0.2945692241191864,\n",
       "  0.290037602186203,\n",
       "  0.28378987312316895,\n",
       "  0.27842798829078674,\n",
       "  0.2731870114803314,\n",
       "  0.26887935400009155,\n",
       "  0.2623770833015442,\n",
       "  0.25927266478538513,\n",
       "  0.25330111384391785,\n",
       "  0.24962440133094788,\n",
       "  0.24580420553684235,\n",
       "  0.24077436327934265,\n",
       "  0.23708906769752502,\n",
       "  0.23274807631969452,\n",
       "  0.22923259437084198,\n",
       "  0.22542206943035126],\n",
       " 'val_accuracy': [0.8360000252723694,\n",
       "  0.847000002861023,\n",
       "  0.8546000123023987,\n",
       "  0.8579999804496765,\n",
       "  0.8672000169754028,\n",
       "  0.8715999722480774,\n",
       "  0.8751999735832214,\n",
       "  0.8744000196456909,\n",
       "  0.8501999974250793,\n",
       "  0.8799999952316284,\n",
       "  0.8784000277519226,\n",
       "  0.8781999945640564,\n",
       "  0.8748000264167786,\n",
       "  0.8844000101089478,\n",
       "  0.8889999985694885,\n",
       "  0.8880000114440918,\n",
       "  0.8873999714851379,\n",
       "  0.8913999795913696,\n",
       "  0.8885999917984009,\n",
       "  0.890999972820282,\n",
       "  0.8884000182151794,\n",
       "  0.8871999979019165,\n",
       "  0.8848000168800354,\n",
       "  0.8885999917984009,\n",
       "  0.8948000073432922,\n",
       "  0.8902000188827515,\n",
       "  0.8952000141143799,\n",
       "  0.8924000263214111,\n",
       "  0.8902000188827515,\n",
       "  0.8992000222206116],\n",
       " 'val_loss': [0.4991224706172943,\n",
       "  0.44322192668914795,\n",
       "  0.4243086874485016,\n",
       "  0.40679264068603516,\n",
       "  0.3782585859298706,\n",
       "  0.3692878186702728,\n",
       "  0.35891884565353394,\n",
       "  0.36015021800994873,\n",
       "  0.40133294463157654,\n",
       "  0.34202882647514343,\n",
       "  0.34170815348625183,\n",
       "  0.3462221622467041,\n",
       "  0.3387537896633148,\n",
       "  0.3278432786464691,\n",
       "  0.3124482333660126,\n",
       "  0.31436607241630554,\n",
       "  0.31926295161247253,\n",
       "  0.3106759786605835,\n",
       "  0.3076481223106384,\n",
       "  0.3044787347316742,\n",
       "  0.31067800521850586,\n",
       "  0.3151590824127197,\n",
       "  0.3085993826389313,\n",
       "  0.3065856695175171,\n",
       "  0.2939961552619934,\n",
       "  0.30587491393089294,\n",
       "  0.29634854197502136,\n",
       "  0.30271223187446594,\n",
       "  0.30032312870025635,\n",
       "  0.2855371832847595]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.history # dictionary containing the loss and performance metrics it measured at the end of each epoch on the training and\n",
    "            # validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0dfd3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da8bdb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(fit.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8e20fae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967df41",
   "metadata": {},
   "source": [
    "The training and validation curves are close which means the model is not overfitting. In addition the loss is decreasing and the accuracy is increasing which means we could keep on training until they converge.\n",
    "\n",
    "We could improve performance by tuning the number of layers, the number of neurons per layer, the types of activation functions we use for each hidden layer, the number of epochs, the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4c3c0a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.8498 - loss: 64.5316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[68.0980224609375, 0.8432000279426575]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2aea0a",
   "metadata": {},
   "source": [
    "## Using the Model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5ae680c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[-3:]\n",
    "y_proba = model.predict(X_new)\n",
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8eac805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bag', 'Trouser', 'Sandal'], dtype='<U11')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "80e87f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe9c17",
   "metadata": {},
   "source": [
    "# Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "caa7d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e6b6dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e5c19677",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c1abf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "eb93a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ayanle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "82ef17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "75f2460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - loss: 1.5027 - val_loss: 0.7742\n",
      "Epoch 2/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.5232 - val_loss: 0.4924\n",
      "Epoch 3/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.4694 - val_loss: 0.4764\n",
      "Epoch 4/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 0.4421 - val_loss: 0.4672\n",
      "Epoch 5/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 0.4456 - val_loss: 0.4272\n",
      "Epoch 6/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 0.4388 - val_loss: 0.4229\n",
      "Epoch 7/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 0.4163 - val_loss: 0.4088\n",
      "Epoch 8/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 0.3980 - val_loss: 0.4008\n",
      "Epoch 9/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.4014 - val_loss: 0.4075\n",
      "Epoch 10/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.4190 - val_loss: 0.4036\n",
      "Epoch 11/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.3799 - val_loss: 0.3962\n",
      "Epoch 12/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.3985 - val_loss: 0.3894\n",
      "Epoch 13/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.3874 - val_loss: 0.3878\n",
      "Epoch 14/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.3853 - val_loss: 0.3899\n",
      "Epoch 15/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.3818 - val_loss: 0.4022\n",
      "Epoch 16/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 0.3717 - val_loss: 0.5292\n",
      "Epoch 17/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.3685 - val_loss: 0.3927\n",
      "Epoch 18/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.3712 - val_loss: 0.3856\n",
      "Epoch 19/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.3647 - val_loss: 0.3802\n",
      "Epoch 20/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.3660 - val_loss: 0.3767\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train_scaled, y_train, epochs=20, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cf246f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 0.3326\n"
     ]
    }
   ],
   "source": [
    "mse_test = model2.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8fe46fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test_scaled[:3]\n",
    "y_pred = model2.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f99eef7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1120763],\n",
       "       [0.9620697],\n",
       "       [0.8577667]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af36d55",
   "metadata": {},
   "source": [
    "# Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bed58f",
   "metadata": {},
   "source": [
    "One example of a non-sequential neural network is a Wide and Deep neural network. This type of neural network connects part or all of the inputs directly to the output layer which makes it possible to learn deep patterns (through the deep path) and simple patterns through the short path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "562abf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model2 = keras.models.Model(inputs=[input], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42361b6",
   "metadata": {},
   "source": [
    "1. We created an input object\n",
    "2. We create the first hidden layer with 30 neurons and relu activation and pass it the input.\n",
    "3. Then we have a second hidden layer and pass it the output of the first hidden layer.\n",
    "4. We then create a concatenate() layer to concatenate the input and output of the second hidden layer.\n",
    "5. We then have an output layer where pass the results of the concatenation.\n",
    "6. We then have a keras model where we specify which inputs and outputs to use.\n",
    "\n",
    "From here we can compile the model, train it, evaluate it and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7582e12",
   "metadata": {},
   "source": [
    "What if we want to send some of the training features through the wide path and some through the deep path. In this case one would use multiple inputs. In the following we will send 5 features through the wide path and six features through the deep path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8e86889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name='wide')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model2 = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "32057860",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mean_squared_error', optimizer = keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f2b1f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train_scaled[:, :5], X_train_scaled[:, 2:]\n",
    "X_val_A, X_val_B = X_val_scaled[:, :5], X_val_scaled[:, 2:]\n",
    "X_test_A, X_test_B = X_test_scaled[:, :5], X_test_scaled[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79002b5",
   "metadata": {},
   "source": [
    "From here we can compile the model, train it, evaluate it and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ccf37309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - loss: 3.2548 - val_loss: 0.8683\n",
      "Epoch 2/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.7550 - val_loss: 0.6589\n",
      "Epoch 3/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.6210 - val_loss: 0.6127\n",
      "Epoch 4/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.5682 - val_loss: 0.5921\n",
      "Epoch 5/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.5552 - val_loss: 0.5714\n",
      "Epoch 6/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.5237 - val_loss: 0.5551\n",
      "Epoch 7/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.5245 - val_loss: 0.5519\n",
      "Epoch 8/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 0.5071 - val_loss: 0.5524\n",
      "Epoch 9/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.4962 - val_loss: 0.5282\n",
      "Epoch 10/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 0.5102 - val_loss: 0.5215\n",
      "Epoch 11/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 0.4958 - val_loss: 0.5155\n",
      "Epoch 12/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 0.4826 - val_loss: 0.5052\n",
      "Epoch 13/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.4776 - val_loss: 0.5114\n",
      "Epoch 14/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 0.4856 - val_loss: 0.4971\n",
      "Epoch 15/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.4750 - val_loss: 0.5015\n",
      "Epoch 16/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.4774 - val_loss: 0.4930\n",
      "Epoch 17/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 0.4816 - val_loss: 0.4888\n",
      "Epoch 18/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.4598 - val_loss: 0.4879\n",
      "Epoch 19/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 0.4635 - val_loss: 0.4904\n",
      "Epoch 20/20\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.4588 - val_loss: 0.4823\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 0.4325\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    " validation_data=((X_val_A, X_val_B), y_val))\n",
    "mse_test = model2.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "df89b23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.4164852 ],\n",
       "        [0.79777217],\n",
       "        [1.0377274 ]], dtype=float32),\n",
       " array([0.98 , 1.086, 0.768]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "y_pred = model2.predict((X_new_A, X_new_B))\n",
    "y_pred, y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f366e",
   "metadata": {},
   "source": [
    "### Multiple Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee6cdd",
   "metadata": {},
   "source": [
    "There are cases where we may have to use multiple outputs. For example if we want to locate and classify the coordinates of the main object in a picture. This is both regression and classification. We can add extra outputs using the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "73528ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = keras.layers.Dense(1, name='main_output')(concat) # same main output as above\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model2 = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cacccb3",
   "metadata": {},
   "source": [
    "Each output has its own loss function. Keras will compute the losses and add them up and so we should priotise which model we are more interested in by giving it more weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "38bdfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=['mse', 'mse'], loss_weights =[0.9, 0.1], optimizer='sgd') # we give more weight to the main output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ba6e742e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - aux_output_loss: 0.2880 - loss: 1.2329 - main_output_loss: 0.9449 - val_aux_output_loss: 0.0926 - val_loss: 0.5332 - val_main_output_loss: 0.4353\n",
      "Epoch 2/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - aux_output_loss: 0.0856 - loss: 0.5217 - main_output_loss: 0.4361 - val_aux_output_loss: 0.0774 - val_loss: 0.5069 - val_main_output_loss: 0.4238\n",
      "Epoch 3/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - aux_output_loss: 0.0718 - loss: 0.4757 - main_output_loss: 0.4039 - val_aux_output_loss: 0.0779 - val_loss: 0.4876 - val_main_output_loss: 0.4048\n",
      "Epoch 4/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - aux_output_loss: 0.0691 - loss: 0.4673 - main_output_loss: 0.3982 - val_aux_output_loss: 0.0720 - val_loss: 0.5049 - val_main_output_loss: 0.4270\n",
      "Epoch 5/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - aux_output_loss: 0.0658 - loss: 0.4511 - main_output_loss: 0.3853 - val_aux_output_loss: 0.0676 - val_loss: 0.4588 - val_main_output_loss: 0.3861\n",
      "Epoch 6/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - aux_output_loss: 0.0637 - loss: 0.4396 - main_output_loss: 0.3759 - val_aux_output_loss: 0.0652 - val_loss: 0.4651 - val_main_output_loss: 0.3952\n",
      "Epoch 7/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - aux_output_loss: 0.0613 - loss: 0.4435 - main_output_loss: 0.3822 - val_aux_output_loss: 0.0638 - val_loss: 0.4507 - val_main_output_loss: 0.3818\n",
      "Epoch 8/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - aux_output_loss: 0.0629 - loss: 0.5056 - main_output_loss: 0.4427 - val_aux_output_loss: 0.0661 - val_loss: 0.4898 - val_main_output_loss: 0.4175\n",
      "Epoch 9/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - aux_output_loss: 0.0578 - loss: 0.4172 - main_output_loss: 0.3594 - val_aux_output_loss: 0.0605 - val_loss: 0.4473 - val_main_output_loss: 0.3822\n",
      "Epoch 10/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - aux_output_loss: 0.0588 - loss: 0.4124 - main_output_loss: 0.3537 - val_aux_output_loss: 0.0586 - val_loss: 0.4529 - val_main_output_loss: 0.3897\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit([X_train_A, X_train_B], [y_train, y_train], epochs=10, validation_data = ([X_val_A, X_val_B], [y_val, y_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dd7dddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - aux_output_loss: 0.0554 - loss: 0.3739 - main_output_loss: 0.3185\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model2.evaluate(\n",
    " [X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "197d1d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model2.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1d4fc6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.34879  ],\n",
       "        [0.7728837],\n",
       "        [1.0779507]], dtype=float32),\n",
       " array([[1.3425562],\n",
       "        [1.1236522],\n",
       "        [1.232836 ]], dtype=float32))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f4067",
   "metadata": {},
   "source": [
    "# Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aba45c",
   "metadata": {},
   "source": [
    "Both the Sequential API and the Functional API work by declaring which layers we want to use and how these layers should be connected. Although this has many advantages sometimes it's better to use an API which unlike the Sequential and Functional APIs can handle dynamic behaviours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7e93f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model): \n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.Concatenate([input_A, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19d311",
   "metadata": {},
   "source": [
    "The first part is a constructor where we build the layers for the model and in the second part we use the layers. The good thing about this API is that now we can use for loops, if statements and many other things.\n",
    "\n",
    "The downside is since the architecture is hidden within the call() function it cannot save or clone the model and even the summary() method does not work as intended. This API should only be used if the flexibility is really needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cebe9a",
   "metadata": {},
   "source": [
    "# Saving & Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3d296f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2.keras') # This saves all the hyperparamters of each layers, optimizers and all the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cda9e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('model.h5') # This loads the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66504003",
   "metadata": {},
   "source": [
    "When training lasts hours then it is useful to save checkpoints at regular intervals during training. We can do this using callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1ce1c",
   "metadata": {},
   "source": [
    "# Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d78d3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('model2.keras') # saves checkpoints at regular intervals \n",
    "                                                            # by default at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "82c8ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mse', optimizer='sgd', loss_weights=[0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9edf0e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - aux_output_loss: 0.0551 - loss: 0.3874 - main_output_loss: 0.3323\n",
      "Epoch 2/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - aux_output_loss: 0.0545 - loss: 0.3872 - main_output_loss: 0.3327\n",
      "Epoch 3/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - aux_output_loss: 0.0542 - loss: 0.3852 - main_output_loss: 0.3310\n",
      "Epoch 4/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - aux_output_loss: 0.0521 - loss: 0.3785 - main_output_loss: 0.3264\n",
      "Epoch 5/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - aux_output_loss: 0.0503 - loss: 0.3664 - main_output_loss: 0.3161\n",
      "Epoch 6/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - aux_output_loss: 0.0521 - loss: 0.3858 - main_output_loss: 0.3338\n",
      "Epoch 7/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - aux_output_loss: 0.0495 - loss: 0.3647 - main_output_loss: 0.3152\n",
      "Epoch 8/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - aux_output_loss: 0.0494 - loss: 0.3687 - main_output_loss: 0.3194\n",
      "Epoch 9/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - aux_output_loss: 0.0480 - loss: 0.3624 - main_output_loss: 0.3144\n",
      "Epoch 10/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - aux_output_loss: 0.0487 - loss: 0.3611 - main_output_loss: 0.3124\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit([X_train_A,X_train_B], [y_train, y_train], epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "29e56b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - aux_output_loss: 0.0458 - loss: 0.3538 - main_output_loss: 0.3080 - val_aux_output_loss: 0.0491 - val_loss: 0.3750 - val_main_output_loss: 0.3232\n",
      "Epoch 2/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - aux_output_loss: 0.0480 - loss: 0.3648 - main_output_loss: 0.3168 - val_aux_output_loss: 0.0482 - val_loss: 0.3693 - val_main_output_loss: 0.3182\n",
      "Epoch 3/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - aux_output_loss: 0.0455 - loss: 0.3485 - main_output_loss: 0.3030 - val_aux_output_loss: 0.0500 - val_loss: 0.3702 - val_main_output_loss: 0.3164\n",
      "Epoch 4/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - aux_output_loss: 0.0471 - loss: 0.3654 - main_output_loss: 0.3183 - val_aux_output_loss: 0.0480 - val_loss: 0.3707 - val_main_output_loss: 0.3199\n",
      "Epoch 5/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - aux_output_loss: 0.0445 - loss: 0.3431 - main_output_loss: 0.2987 - val_aux_output_loss: 0.0483 - val_loss: 0.3737 - val_main_output_loss: 0.3203\n",
      "Epoch 6/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - aux_output_loss: 0.0455 - loss: 0.3570 - main_output_loss: 0.3115 - val_aux_output_loss: 0.0468 - val_loss: 0.3973 - val_main_output_loss: 0.3457\n",
      "Epoch 7/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - aux_output_loss: 0.0453 - loss: 0.3584 - main_output_loss: 0.3131 - val_aux_output_loss: 0.0459 - val_loss: 0.3800 - val_main_output_loss: 0.3288\n",
      "Epoch 8/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - aux_output_loss: 0.0428 - loss: 0.3356 - main_output_loss: 0.2928 - val_aux_output_loss: 0.0458 - val_loss: 0.3608 - val_main_output_loss: 0.3117\n",
      "Epoch 9/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - aux_output_loss: 0.0432 - loss: 0.3442 - main_output_loss: 0.3010 - val_aux_output_loss: 0.0459 - val_loss: 0.3614 - val_main_output_loss: 0.3105\n",
      "Epoch 10/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - aux_output_loss: 0.0436 - loss: 0.3456 - main_output_loss: 0.3020 - val_aux_output_loss: 0.0438 - val_loss: 0.3612 - val_main_output_loss: 0.3124\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('model2.keras', save_best_only=True) # saves only best model\n",
    "history = model2.fit([X_train_A, X_train_B], [y_train, y_train], \n",
    "                    validation_data = ([X_val_A, X_val_B], [y_val, y_val]), epochs=10, \n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04313b3",
   "metadata": {},
   "source": [
    "We can use callbacks with early stopping to save time and resources. This works by because the callback saves the best model and early stopping interupts training when there is no progress on the validation set for a number of epochs (defined by the patience argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cd2e6f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - aux_output_loss: 0.0426 - loss: 0.3441 - main_output_loss: 0.3015 - val_aux_output_loss: 0.0443 - val_loss: 0.3834 - val_main_output_loss: 0.3370\n",
      "Epoch 2/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - aux_output_loss: 0.0433 - loss: 0.3468 - main_output_loss: 0.3034 - val_aux_output_loss: 0.0440 - val_loss: 0.3874 - val_main_output_loss: 0.3403\n",
      "Epoch 3/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - aux_output_loss: 0.0406 - loss: 0.3270 - main_output_loss: 0.2864 - val_aux_output_loss: 0.0446 - val_loss: 0.3772 - val_main_output_loss: 0.3276\n",
      "Epoch 4/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - aux_output_loss: 0.0416 - loss: 0.3390 - main_output_loss: 0.2974 - val_aux_output_loss: 0.0453 - val_loss: 0.3848 - val_main_output_loss: 0.3367\n",
      "Epoch 5/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - aux_output_loss: 0.0432 - loss: 0.3431 - main_output_loss: 0.2999 - val_aux_output_loss: 0.0421 - val_loss: 0.3549 - val_main_output_loss: 0.3086\n",
      "Epoch 6/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - aux_output_loss: 0.0411 - loss: 0.3365 - main_output_loss: 0.2954 - val_aux_output_loss: 0.0414 - val_loss: 0.3472 - val_main_output_loss: 0.3013\n",
      "Epoch 7/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - aux_output_loss: 0.0399 - loss: 0.3222 - main_output_loss: 0.2823 - val_aux_output_loss: 0.0411 - val_loss: 0.3454 - val_main_output_loss: 0.2994\n",
      "Epoch 8/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - aux_output_loss: 0.0409 - loss: 0.3322 - main_output_loss: 0.2914 - val_aux_output_loss: 0.0424 - val_loss: 0.3575 - val_main_output_loss: 0.3134\n",
      "Epoch 9/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - aux_output_loss: 0.0417 - loss: 0.3432 - main_output_loss: 0.3015 - val_aux_output_loss: 0.0407 - val_loss: 0.3421 - val_main_output_loss: 0.2965\n",
      "Epoch 10/10\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - aux_output_loss: 0.0401 - loss: 0.3271 - main_output_loss: 0.2871 - val_aux_output_loss: 0.0409 - val_loss: 0.3489 - val_main_output_loss: 0.3033\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights=True)\n",
    "history = model2.fit([X_train_A, X_train_B], [y_train, y_train], \n",
    "                    validation_data = ([X_val_A, X_val_B], [y_val, y_val]), epochs=10, \n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55a301",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aee00b",
   "metadata": {},
   "source": [
    "In order to use gridsearch we need to wrap the keras models in objects that are similar to Scikit-Learn Regressors. First we will create a function that will build and compile a keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b1914812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "60a607cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.model.Sequential()\n",
    "    options = {'input_shape': input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu', **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "78eadc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = KerasRegressor(build_model) # We did not provide hyperparameters, it will use the default ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bdfe99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "aa73aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden': [0, 1, 2, 3],\n",
    "    'n_neurons': np.arange(1, 100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "random_search_cv = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distribs,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring = 'neg_mean_squared_error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
